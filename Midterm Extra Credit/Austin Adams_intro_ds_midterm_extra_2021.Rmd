---
title: "Midterm Exam - Extra Credit"
subtitle: Austin Adams
output:
  html_document:
    df_print: paged
---
# Problem 1

- Load the `tidyverse` package

```{r, message = FALSE, warning = FALSE}
library(tidyverse)
```

Consider the `iris` dataset. It is one of the built-in datasets in your R installation. 

The data set was created by statistician Ronald Fisher in his 1936 paper _"The use of multiple measurements in taxonomic problems"_.  

- The data consists of **3 classes** of flower types: setosa, virginica, versicolor.
  
- The data has **4 attributes**: sepal width, sepal length, petal width, petal length


This famous `iris` data set gives the measurements in centimeters of the variables sepal length and width and petal length and width, respectively, for 50 flowers from each of 3 species of iris. The species are Iris setosa, versicolor, and virginica.

The built-in data set `iris` is a data frame with 150 cases (rows) and 5 variables (columns) named `Sepal.Length`, `Sepal.Width`, `Petal.Length`, `Petal.Width`, and `Species`.

![](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/iris-machinelearning.png)


```{r}
head(iris) #quick look at the best ranked ones
glimpse(iris)
```


(a) (1 point) Create a variable called `myid` that contains the result of multiplying $\pi$ by the 3-4 digit number in your university email, and dividing by 1000.

```{r}
myid <- (pi*0230)/1000 #multiplied by pi and then divide that function by 1000
myid #calling that variable 
```



(b) (2 points) Use a **histogram** to explore the distribution of one of the numerical variables in the dataset.



```{r}
# use ggplot to create the histogram
ggplot(y = iris$Petal.Length) + #creates plot
  geom_bar(mapping = aes(x = iris$Petal.Length, fill = iris$Petal.Length)) #wanting it to have petal length of the iris as x axis and count it based how many times it occurs. 
```
```{r}
ggplot(data = iris) + #uses the data set as the basis for later
  geom_histogram(mapping = aes(x = Petal.Length)) #better way to go about creating a histogram
```


(c) (2 points) Create side-by-side box plots that show the distribution of the numerical variable you chose in part (a) for the 3 different types of `Species`. _Make sure to comment on your results_.

```{r}
# use ggplot to create the boxplots
ggplot(data=iris, aes(y=Petal.Length, x = Species, fill = Species))+geom_boxplot() #this is taking the data set iris and looking at the Petal Lengths for each different species. I have it colored differently depending on the species and made it into boxplots. 
```
This box plot indicates that the Setosa species has an incredibly small petal length range and petal length. It appears that it has a range of about 1-1.75 in length. 
The Veriscolor has a greater petal range and length. It appears, based on the box plot, to have a range from 4-4.75 in petal length. 
The Virginica has the largest petal lengths and greatest range. It ranges from 5 to ~6 in petal length! 
Overall, the Virginica has the largest petal lengths and range with the Setosa having the smallest of both. 

(d) (2 points) Create a summary with the average `Petal.Length` and `Petal.Width` per `Species`.

```{r}
iris %>% #data set
  group_by(Species) %>% #wanting it "per species"
  summarise(Avg_Petal_length = mean(Petal.Length), Avg_Petal_width= mean(Petal.Width)) #averaging out the petal length and width for each. 
```


(e) (2 points) Create a new data frame called `my_iris` in which all numerical attributes have been transformed from centimeters to millimeters.

```{r}
my_iris <- iris #assigning the old data set to the one I'm creating
my_iris[1:4] <- my_iris[1:4]*10 #wanting it to select the first four columns. What this does is it includes all the number values that need to be multiplied and ignores the species name as that is the 5th. State that the new 4 are equal to the old values X 10 to obtain the conversion
my_iris #print out that data set
```

(f) (2 points) Use the variable `myid` from part (a) to obtain all the observations from your `my_iris` data frame for which the sepal length (in millimeters) is greater than or equal to `myid`
```{r}
  my_iris %>% #data set we just made
  filter(Sepal.Length >= myid) #filtering it to be Sepal.Length to be greater or equal to my id (which shocker, it's a lot)
```
 
# Problem 2
The data for this problem contains songs from the Billboard Hot 100 list ranging from 1960 to 2015

```{r, message=FALSE}
music_path <- "https://raw.githubusercontent.com/reisanar/datasets/master/bbTop100.csv"
music_top100 <- read.csv(music_path)
```

Some of the variables included in this dataset are the `year` the song came out, the `artist_name`, `duration` (in milliseconds), among others. 


Variable Name |   Description
--------------|---------------------------------------------------
`year`          | year
`artist_name`   | the artist of the song
`explicit`      | if the track is rated as explicit
`track_name`    | the name of the track
`danceability`  | describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable.
`energy`        | is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale. Perceptual features contributing to this attribute include dynamic range, perceived loudness, timbre, onset rate, and general entropy.
`key`           | The key the track is in. Integers map to pitches using standard Pitch Class notation. E.g. 0 = C, 1 = C#/Db, 2 = D, and so on.
`loudness`      | The overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks. Loudness is the quality of a sound that is the primary psychological correlate of physical strength (amplitude). Values typical range between -60 and 0 db.
`mode`          | indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0.
`speechiness`   | detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0. Values above 0.66 describe tracks that are probably made entirely of spoken words. Values between 0.33 and 0.66 describe tracks that may contain both music and speech, either in sections or layered, including such cases as rap music. Values below 0.33 most likely represent music and other non-speech-like tracks.
`acousticness`  | A confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic.
`instrumentalness`  | Predicts whether a track contains no vocals. "Ooh" and "aah" sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly "vocal". The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content. Values above 0.5 are intended to represent instrumental tracks, but confidence is higher as the value approaches 1.0.
`liveness`      | Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live. A value above 0.8 provides strong likelihood that the track is live.
`valence`       | A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).
`tempo`         | The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration.
`duration_ms`   | The duration of the track in milliseconds.

```{r}
glimpse(music_top100) #wanting to take a look at the names of the columns
```


(a) (1 point) Find all the songs from 2013


```{r}
# use filter()
  music_top100 %>% #data set
  filter(year == "2013") #filters it by year
```


(b) (2 points) Make a new variable `duration_min` to convert **from milliseconds to minutes**

```{r}
# hint: use the mutate() function
music_top100 <- music_top100 %>% #data set
  mutate(duration_min = (duration_ms / 60000)) #takes the conversion rate of 60,000 ms to one second

music_top100
```



(c) (2 points) Check the **distribution of duration of songs**. Use a histogram for the variable `duration_min` with `binwidth=0.5`


```{r}
ggplot(data = music_top100)+ #data set
  geom_histogram(aes(x=duration_min), binwidth = 0.5) #binwidth outside
```


(d) (2 points) Are there songs longer than 10 minutes? If so, what are the years when such songs were part of the Top 100 list?

```{r}
# use the filter() function
music_top100 %>% #data set
  filter(duration_min > 10) %>% #wanting to filter it by the songs that are greater than 10 minutes
  select(year) #selecting the column with the inputs that are satisfied after the filter

```



(e) (2 points) How would you find the exact number of "explicit" songs that were part of the "Top 100 List" per year?


```{r}
# number of explicit songs per year
music_top100 %>% #data set
  group_by(year)%>% #grouped by year
  filter(explicit == "TRUE") %>% #selecting only those that are explicit 
  summarise(total_explicit = n()) #counting them 
```
```{r}
#another way to do this is....
music_top100 %>%
  group_by(year, explicit) %>%
  count()
```

```{r}
music_top100 %>%
  group_by(year, explicit) %>%
  count() %>%
  filter(year > 2010) %>% #after this line we use the plus not the pipe
  ggplot() + geom_col(aes(x = year, y = n, fill = explicit), position = "dodge") #enables it to be next to each other. Not using the position they would be stacked on top of each other
```

### Tell us something we don't know (Extra credit: up to 3 points)
Looking at Justin Timberlake
```{r}
music_top100 %>%
  filter(artist_name == "Justin Timberlake")

```


- This is your chance to be creative and explore the data set in a way we have not done yet. 

- Think of a question you may be able to answer with the number of observations and variables included in the dataset. Make sure to write down the question and list the steps you might need to execute in order to provide an answer to the question. 

As a sound technician, people always say that the music "feels better" when it's louder. Personally, I have also always pushed the decibels when the song had a higher tempo as it felt more energetic and "fun". Currently, I would assume that due to cultural trends, that this increased throughout the years. As a result, I am preliminarily interested in looking at loudness and tempo of the music throughout the years. 

```{r}
new_loudness <- music_top100 %>% #assigned a variable to the old data set
  group_by(year) %>% #filtered by year
  summarise(loudness = mean(loudness))#grabbing the average values year over year

ggplot(new_loudness, aes(x = year, y = loudness))+ geom_point(size = 3)+geom_smooth(method = "lm")#data set looking at loudness in comparison to the year. Adding sizable data points to make it easier to see. Added a linear regression line to the data to make it easy to extrapolate the trend.
```
This graph indicates that year over year, the average loudness of the top 100 songs have increased. My assumption is already "half correct" as we have seen a progression of db levels. 


```{r}
new_tempo <- music_top100 %>% #assigning this to a new data set
  group_by(year) %>% #looking at it by year
  summarise(tempo = mean(tempo)) #grabbing the average values year over year

ggplot(new_tempo, aes(x = year, y = tempo))+ geom_point(size = 3)+geom_smooth(method = "lm") #data set looking at tempo in comparison to the year. Adding sizable data points to make it easier to see. Added a linear regression line to the data to make it easy to extrapolate the trend. 
```
This graph indicates that year over year, the average tempo of the top 100 song has no significant trend. As a result of this, my entire assumption that there was correlation between loudness and tempo throughout the years is not entirely valid. Looks like sound technicians pushing the db level was better for a top 100 song rather than the tempo of the song itself.   



After seeing the db level increasing year over year, I also decided I wanted to check out the energy of these songs throughout the years. According to the data set, energetic tracks feel fast, loud, and noisy. 
So I decided to see how the energy levels looks. 

```{r}
new_energy <- music_top100 %>% #assigned new variable to old data set
  group_by(year) %>% #filtered by year
  summarise(energy = mean(energy))#grabbing the average values year over year

ggplot(new_energy, aes(x = year, y = energy))+ geom_point(size = 3)+geom_smooth(method = "lm")#data set looking at energy in comparison to the year. Adding sizable data points to make it easier to see. Added a linear regression line to the data to make it easy to extrapolate the trend.
```

This graph indicates that year over year, the average energy of the top 100 song have increased. This makes sense as the data set indicates energetic tracks feel fast, loud, and noisy. 

We saw previously that the db levels increased throughout the years, so it is understandable that the energy also is increasing. 
However the "feeling of speed" clearly does not match with the actual tempo of the song. 
So I guess I should keep pushing the db level to get an "energetic" feel regardless of tempo. :)

Also looked at average loudness and tempo with direct comparison with one another. 

```{r}
added <- music_top100 %>% #assigned new variable to old data set
  group_by(year) %>%
  summarise(avg_loudness = mean(loudness), avg_tempo = mean(tempo))#grabbing the average values year over year

ggplot(added, aes(x = avg_loudness, y = avg_tempo, color = year)) + geom_point(size = 3)+geom_smooth(method = "lm") #color by year to use a gradient
```

It hardly slopes upwards. 
